{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!aws s3 cp s3://msan694-group/final_nba.csv final_nba.csv\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10466d6d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'label,shot_number,dribbles,touch_time,shot_dist,pts_type,close_def_dist,home,time,matching_pos,consec_shots,shooter_c,shooter_pf,shooter_pg,shooter_pg_sg,shooter_sf,shooter_sg,shooter_sg_pg,defender_c,defender_pf,defender_pf_sf,defender_pg,defender_pg_sg,defender_sf,defender_sf_pf,defender_sf_sg,defender_sg,defender_sg_pg,defender_sg_sf,dps,shot_clock,shotnum_shotdist,dribble_touch,shotdist_defdist,touch_shotdist',\n",
       " u'1,1,2,1.9,7.7,2,1.3,0,10.85,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1.052631579,10.8,7.7,3.8,10.01,14.63',\n",
       " u'0,2,0,0.8,28.2,3,6.1,0,11.76666667,0,1,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,3.4,56.4,0,172.02,22.56',\n",
       " u'0,3,3,2.7,10.1,2,0.9,0,12,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1.111111111,0,30.3,8.1,9.09,27.27',\n",
       " u'0,4,2,1.9,17.2,2,3.4,0,12.21666667,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,1.052631579,10.3,68.8,3.8,58.48,32.68']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rdd_vec = sc.textFile(\"final_nba.csv\")\n",
    "rdd_vec = sc.textFile(\"NBA_Int2.csv\")\n",
    "header = rdd_vec.first() #extract header\n",
    "rdd_vec.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128069"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = rdd_vec.filter(lambda row: row not in header) #filter out the header!\n",
    "new_rdd = data.map(lambda line: line.split(',')) # split the wide vector by \",\"\n",
    "new_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  1.0|[1.0,2.0,1.9,7.7,...|\n",
      "|  0.0|[2.0,0.0,0.8,28.2...|\n",
      "|  0.0|[3.0,3.0,2.7,10.1...|\n",
      "|  0.0|[4.0,2.0,1.9,17.2...|\n",
      "|  0.0|[5.0,2.0,2.7,3.7,...|\n",
      "|  0.0|[6.0,2.0,4.4,18.4...|\n",
      "|  0.0|[7.0,11.0,9.0,20....|\n",
      "|  1.0|[8.0,3.0,2.5,3.5,...|\n",
      "|  0.0|[9.0,0.0,0.8,24.6...|\n",
      "|  0.0|[1.0,0.0,1.1,22.4...|\n",
      "|  0.0|[2.0,8.0,7.5,24.5...|\n",
      "|  1.0|[3.0,14.0,11.9,14...|\n",
      "|  1.0|[4.0,2.0,2.9,5.9,...|\n",
      "|  0.0|[1.0,0.0,0.8,26.4...|\n",
      "|  0.0|[1.0,0.0,0.5,22.8...|\n",
      "|  1.0|[2.0,3.0,2.7,24.7...|\n",
      "|  0.0|[3.0,6.0,5.1,25.0...|\n",
      "|  0.0|[4.0,1.0,0.9,25.6...|\n",
      "|  1.0|[5.0,0.0,1.2,24.2...|\n",
      "|  0.0|[1.0,2.0,2.2,25.4...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#turn to Vectors.dense (with label out front)\n",
    "split_rdd = new_rdd.map(lambda line: (float(line[0]), Vectors.dense([float(c) for c in line[1:len(line)]]))) \n",
    "\n",
    "# Create the DataFrame from the collected RDD\n",
    "full_df = sqlContext.createDataFrame(split_rdd.collect(), [\"label\", \"features\"])\n",
    "full_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 ms, sys: 1.21 ms, total: 3.26 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "(trainingData, testData) = full_df.randomSplit([0.7, 0.3])\n",
    "trainingData = trainingData.cache()\n",
    "testData = testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(label=0.0, features=DenseVector([1.0, 0.0, 0.0, 0.1, 2.0, 1.6, 0.0, 9.9333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.0, 0.16, 0.0]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbt = GBTClassifier(maxIter=2, maxDepth=2, labelCol=\"label\", maxBins=3)\n",
    "pipeline = Pipeline(stages=[gbt])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|  0.0|[1.0,0.0,-0.3,18....|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,2.2,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.0,7.2,...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,13.7...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,24.5...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.1,26.6...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.3,3.2,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.4,4.1,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.4,22.2...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.5,3.3,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.5,25.6...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,15.8...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,24.4...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,24.9...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,1.4,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.7,1.6,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.7,2.7,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.7,6.7,...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,17.1...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,21.2...|       0.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 59.8043\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n-fold validation and the results.\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "cv = CrossValidator().setEstimator(gbt).setEvaluator(evaluator).setNumFolds(5)\n",
    "paramGrid = ParamGridBuilder().addGrid(gbt.maxDepth, [3,6]).addGrid(gbt.maxIter, [4,10]).build()\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6168122553720936"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(cvmodel.bestModel.transform(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBTClassificationModel (uid=GBTClassifier_448fb02ee2409dec56ba) with 20 trees"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmodel.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Train the model.\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(regParam=0.01, maxIter=1000, fitIntercept=True)\n",
    "lrmodel = lr.fit(trainingData)\n",
    "lrmodel = lr.setParams(regParam=0.01, maxIter=500, fitIntercept=True).fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|label|            features|rawPrediction|probability|prediction|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "|  0.0|[1.0,0.0,-0.3,18....|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,0.7,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,1.2,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,3.6,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,7.2,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,14.3...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.1,26.6...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.2,1.9,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.2,2.8,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.3,3.2,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.4,14.8...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.5,22.8...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,3.7,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,7.6,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,24.3...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,25.1...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,0.5,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,1.4,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,1.6,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,6.7,...|    [NaN,NaN]|  [NaN,NaN]|       0.0|\n",
      "+-----+--------------------+-------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate models using test dataset.\n",
    "validpredicts = lrmodel.transform(testData)\n",
    "validpredicts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC:0.5\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model. default metric : Area Under ROC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "bceval = BinaryClassificationEvaluator()\n",
    "print (bceval.getMetricName() +\":\" + str(bceval.evaluate(validpredicts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n-fold validation and the results.\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "cv = CrossValidator().setEstimator(lr).setEvaluator(bceval).setNumFolds(5)\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.maxIter, [1000]).addGrid(lr.regParam, [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]).build()\n",
    "cv.setEstimatorParamMaps(paramGrid)\n",
    "cvmodel = cv.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BinaryClassificationEvaluator().evaluate(cvmodel.bestModel.transform(testData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GBTClassificationModel (uid=GBTClassifier_4b05842593e4a7f2e2ac) with 4 trees"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvmodel.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/2.1.0/libexec/python/pyspark/mllib/evaluation.py:237: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6075466804979253"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "dtresrdd = validpredicts.select('prediction','label').rdd\n",
    "dtmm =MulticlassMetrics(dtresrdd)\n",
    "dtmm.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(dtmm.confusionMatrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+----------+\n",
      "|label|            features|prediction|\n",
      "+-----+--------------------+----------+\n",
      "|  0.0|[1.0,0.0,-0.3,18....|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,2.2,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.0,7.2,...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,13.7...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.0,24.5...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.1,26.6...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.3,3.2,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.4,4.1,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.4,22.2...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.5,3.3,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.5,25.6...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,15.8...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,24.4...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.6,24.9...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,1.4,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.7,1.6,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.7,2.7,...|       1.0|\n",
      "|  0.0|[1.0,0.0,0.7,6.7,...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,17.1...|       0.0|\n",
      "|  0.0|[1.0,0.0,0.7,21.2...|       0.0|\n",
      "+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=4)\n",
    "dt_model = dt.fit(trainingData)\n",
    "predictions = model.transform(testData)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       0.0|  0.0|[1.0,0.0,-0.3,18....|\n",
      "|       1.0|  0.0|[1.0,0.0,0.0,2.2,...|\n",
      "|       0.0|  0.0|[1.0,0.0,0.0,7.2,...|\n",
      "|       0.0|  0.0|[1.0,0.0,0.0,13.7...|\n",
      "|       0.0|  0.0|[1.0,0.0,0.0,24.5...|\n",
      "|       0.0|  0.0|[1.0,0.0,0.1,26.6...|\n",
      "|       1.0|  0.0|[1.0,0.0,0.3,3.2,...|\n",
      "|       1.0|  0.0|[1.0,0.0,0.4,4.1,...|\n",
      "|       0.0|  0.0|[1.0,0.0,0.4,22.2...|\n",
      "|       1.0|  0.0|[1.0,0.0,0.5,3.3,...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-----------------+\n",
      "|  avg(prediction)|\n",
      "+-----------------+\n",
      "|0.333549340314679|\n",
      "+-----------------+\n",
      "\n",
      "None\n",
      "+-------------------+\n",
      "|         avg(label)|\n",
      "+-------------------+\n",
      "|0.45042639778117627|\n",
      "+-------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "predictions.select(\"prediction\", \"label\", \"features\").show(10)\n",
    "print predictions.select(avg(\"prediction\")).show()\n",
    "print predictions.select(avg(\"label\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 59.8043\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "\n",
    "print(\"Accuracy = %g\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'DecisionTreeClassificationModel (uid=DecisionTreeClassifier_45e68365f132a6343543) of depth 4 with 31 nodes\\n  If (feature 3 <= 5.8)\\n   If (feature 5 <= 2.9)\\n    If (feature 2 <= 1.5)\\n     If (feature 5 <= 2.1)\\n      Predict: 1.0\\n     Else (feature 5 > 2.1)\\n      Predict: 1.0\\n    Else (feature 2 > 1.5)\\n     If (feature 5 <= 2.3)\\n      Predict: 0.0\\n     Else (feature 5 > 2.3)\\n      Predict: 1.0\\n   Else (feature 5 > 2.9)\\n    If (feature 5 <= 4.6)\\n     If (feature 33 <= 5.46)\\n      Predict: 1.0\\n     Else (feature 33 > 5.46)\\n      Predict: 1.0\\n    Else (feature 5 > 4.6)\\n     If (feature 2 <= 4.1)\\n      Predict: 1.0\\n     Else (feature 2 > 4.1)\\n      Predict: 1.0\\n  Else (feature 3 > 5.8)\\n   If (feature 29 <= 3.1)\\n    If (feature 3 <= 25.2)\\n     If (feature 3 <= 8.4)\\n      Predict: 0.0\\n     Else (feature 3 > 8.4)\\n      Predict: 0.0\\n    Else (feature 3 > 25.2)\\n     If (feature 28 <= 0.5)\\n      Predict: 0.0\\n     Else (feature 28 > 0.5)\\n      Predict: 0.0\\n   Else (feature 29 > 3.1)\\n    If (feature 3 <= 22.5)\\n     If (feature 5 <= 5.3)\\n      Predict: 0.0\\n     Else (feature 5 > 5.3)\\n      Predict: 0.0\\n    Else (feature 3 > 22.5)\\n     If (feature 5 <= 6.2)\\n      Predict: 0.0\\n     Else (feature 5 > 6.2)\\n      Predict: 0.0\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.toDebugString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOUCH_TIME\n",
      "PTS_TYPE\n",
      "DRIBBLES\n",
      "SHOT_DIST\n"
     ]
    }
   ],
   "source": [
    "print header.split(\",\")[3]\n",
    "print header.split(\",\")[5]\n",
    "print header.split(\",\")[2]\n",
    "print header.split(\",\")[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ If Touch_time <= 5.1\n",
    "+ If player shoots for 2, not 3\n",
    "+ If dribbles < 1.4\n",
    "+ **predict 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(34, {2: 0.054, 3: 0.6169, 5: 0.255, 28: 0.0051, 29: 0.042, 33: 0.027})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dribbles\n",
      "touch_time\n",
      "pts_type\n",
      "defender_sg_sf\n",
      "dps\n",
      "shotdist_defdist\n"
     ]
    }
   ],
   "source": [
    "print header.split(\",\")[2]\n",
    "print header.split(\",\")[3]\n",
    "print header.split(\",\")[5]\n",
    "print header.split(\",\")[28]\n",
    "print header.split(\",\")[29]\n",
    "print header.split(\",\")[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(maxDepth = 10,numTrees=10)\n",
    "rfmodel = rf.fit(trainingData)\n",
    "rfpredicts = rfmodel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 59.4074\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(rfpredicts)\n",
    "print(\"Accuracy = %g\" % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/2.1.0/libexec/python/pyspark/mllib/evaluation.py:237: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6198709142279478"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "rfpredicts = rfmodel.transform(testData)\n",
    "rfresrdd = rfpredicts.select('prediction','label').rdd\n",
    "rfmm = MulticlassMetrics(rfresrdd)\n",
    "rfmm.precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 17797.,   3405.],\n",
      "             [ 11260.,   6117.]])\n"
     ]
    }
   ],
   "source": [
    "print rfmm.confusionMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
